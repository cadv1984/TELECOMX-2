{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOC/hHxtHYEti9sW0HptLC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cadv1984/TELECOMX-2/blob/main/TELECOM_X_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSwUKwL_tN0D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción del Archivo"
      ],
      "metadata": {
        "id": "hBHx6Jqzw6Bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código comienza con importar las librerías necesarias como pandas, numpy entre otras. Se carga archivo del proyecto anterior y luego se realiza una limpieza inicial."
      ],
      "metadata": {
        "id": "bA6vM5YU5otI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZ4FODNh5j4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "metadata": {
        "id": "ngE8FF7txAVW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#carga de datos\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv('/content/datos_tratados.csv')\n",
        "except FileNotFoundError:\n",
        "  print(\"El archivo no se encuentra en la ruta especificada.\")\n",
        "except Exception as e:\n",
        "  print(f\"Ocurrió un error al cargar el archivo: {e}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "mDIT2nYDxbe7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#limpiar datos\n",
        "\n",
        "df = df.drop('customerID', axis=1)\n",
        "df['account.Charges.Total'] = pd.to_numeric(df['account.Charges.Total'], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "print ('Formato de los datos luego de la limpieza:')\n",
        "print(df.info())\n",
        "\n",
        "# validar proporción de CHURN\n",
        "\n",
        "churn_porportion = df['Churn'].value_counts(normalize=True)\n",
        "print('\\nProporción de clientes que cancelaron servicio')\n",
        "print(churn_porportion)"
      ],
      "metadata": {
        "id": "vHh5wCHM5cwA",
        "outputId": "fc6bd6a5-752c-4f9a-e914-16c49c8a98c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato de los datos luego de la limpieza:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 7043 entries, 0 to 7266\n",
            "Data columns (total 21 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Churn                      7043 non-null   object \n",
            " 1   customer.gender            7043 non-null   object \n",
            " 2   customer.SeniorCitizen     7043 non-null   int64  \n",
            " 3   customer.Partner           7043 non-null   object \n",
            " 4   customer.Dependents        7043 non-null   object \n",
            " 5   customer.tenure            7043 non-null   int64  \n",
            " 6   phone.PhoneService         7043 non-null   object \n",
            " 7   phone.MultipleLines        7043 non-null   object \n",
            " 8   internet.InternetService   7043 non-null   object \n",
            " 9   internet.OnlineSecurity    7043 non-null   object \n",
            " 10  internet.OnlineBackup      7043 non-null   object \n",
            " 11  internet.DeviceProtection  7043 non-null   object \n",
            " 12  internet.TechSupport       7043 non-null   object \n",
            " 13  internet.StreamingTV       7043 non-null   object \n",
            " 14  internet.StreamingMovies   7043 non-null   object \n",
            " 15  account.Contract           7043 non-null   object \n",
            " 16  account.PaperlessBilling   7043 non-null   object \n",
            " 17  account.PaymentMethod      7043 non-null   object \n",
            " 18  account.Charges.Monthly    7043 non-null   float64\n",
            " 19  account.Charges.Total      7043 non-null   float64\n",
            " 20  Cuentas_Diarias            7043 non-null   float64\n",
            "dtypes: float64(3), int64(2), object(16)\n",
            "memory usage: 1.2+ MB\n",
            "None\n",
            "\n",
            "Proporción de clientes que cancelaron servicio\n",
            "Churn\n",
            "No     0.73463\n",
            "Yes    0.26537\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wfdd2GSxzfXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento de datos y preparación para el modelado\n"
      ],
      "metadata": {
        "id": "eMvryv3szglK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definen las variables categóricas y numéricas para aplicar diferentes transformaciones. La variable objetivo churn se mapea a valores binarios (0 y 1). Luego, se utiliza ColumnTransforme para aplicar OneHotEncoder a las variables categóricas y StandardScaler (normalización) a las variables numéricas. Esta metodología asegura que cada  tipo de dato reciba el procesamiento adecuado antes de ser alimentado a los modelos. Finalmente, los datos se dividen en conjuntos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "1Yfs-wa87L3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# definir varibles categóricas y numéricas\n",
        "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "categorical_features.remove('Churn')  # Ahora 'Churn' sí está en la lista para ser eliminado.\n",
        "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# mapear variable objetivo a valores binarios\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "#separa variables predictoras (X) y variable objetivo (y)\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "#separa los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#one-hot para variables categóricas\n",
        "# normalización (StandarScaler) para variables numéricas\n",
        "preprocessor_lr = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
        "        ('num', StandardScaler(), numerical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        "    )\n",
        "\n",
        "print('Dimensiones de los conjuntos de entrenamiento y prueba:')\n",
        "print('X_train:', X_train.shape)\n",
        "print('X_test:', X_test.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('y_test:', y_test.shape)\n",
        "#\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cswBFmOOziQT",
        "outputId": "e558e5ad-2555-4c4a-eb94-d6305f34c4f2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de los conjuntos de entrenamiento y prueba:\n",
            "X_train: (5634, 20)\n",
            "X_test: (1409, 20)\n",
            "y_train: (5634,)\n",
            "y_test: (1409,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AVVXVGlH9gOx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmHAyzxTB3Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creación y Evaluación de Modelos"
      ],
      "metadata": {
        "id": "8X7xFGuLB3xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modelo 1: regresión logística con normalización\n",
        "\n",
        "pipeline_lr = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_lr),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n",
        "\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "y_pred_lr = pipeline_lr.predict(X_test)\n",
        "\n",
        "print('Métricas del modelo:')\n",
        "print(f'Exactitud:{accuracy_score(y_test, y_pred_lr):.4f}')\n",
        "print(f'Precisión:{precision_score(y_test,y_pred_lr):.4f}')\n",
        "print(f'Recall:{recall_score(y_test, y_pred_lr):.4f}')\n",
        "print(f'F1-Score:{f1_score(y_test, y_pred_lr):.4f}')\n",
        "print(f'\\n Matriz de Confusión:\\n',confusion_matrix(y_test, y_pred_lr))\n",
        "\n",
        "#\n"
      ],
      "metadata": {
        "id": "1wzCCGSb7GKW",
        "outputId": "8e72ddd8-93f9-4511-ee64-605e6c101a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas del modelo:\n",
            "Exactitud:0.7935\n",
            "Precisión:0.6352\n",
            "Recall:0.5214\n",
            "F1-Score:0.5727\n",
            "\n",
            " Matriz de Confusión:\n",
            " [[923 112]\n",
            " [179 195]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0u4Myzc7GHW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}